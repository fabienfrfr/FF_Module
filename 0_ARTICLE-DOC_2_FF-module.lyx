#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine biblatex
\cite_engine_type authoryear
\biblio_style plain
\biblatex_bibstyle savetrees
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 2cm
\bottommargin 3cm
\headheight 2cm
\headsep 2cm
\footskip 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
An Exploration of Evolutionary Neural Network Construction to Find Optimized
 Topology
\end_layout

\begin_layout Author
F.
 Furfaro
\end_layout

\begin_layout Date
2021
\end_layout

\begin_layout Abstract
La conception d'outils...
\end_layout

\begin_layout Part*
Introduction
\end_layout

\begin_layout Standard
Une peu d'histoire
\begin_inset Newline newline
\end_inset

article math : Ludovic arnold : optimisation de la topologie des reseau
 de neurones profonds
\begin_inset Newline newline
\end_inset

Article zoo : a mostly complete chart of neural network
\end_layout

\begin_layout Part*
Méthodes
\end_layout

\begin_layout Standard
Les différentes base de données
\begin_inset Newline newline
\end_inset

Dans le cas d'input grand, comment connecter efficassement les noeud : 
\end_layout

\begin_layout Itemize
cluster de noeud ? par % de bloc ?
\end_layout

\begin_layout Itemize
full aléatoire en configuration initiale
\end_layout

\begin_layout Itemize
partir d'une architecture connu (U-net par exemple)
\end_layout

\begin_layout Itemize
Faire 3 partie dans le reseau : Reduction - Logique - Augmentation ?
\end_layout

\begin_deeper
\begin_layout Itemize
Partie reduction : bloc aléatoire convertissant Grande dimension à plus
 petite
\end_layout

\begin_layout Itemize
Partie logique : traitement de l'information
\end_layout

\begin_layout Itemize
Re-augmentation de l'output (si necessaire) : possible connection avec les
 entrées
\end_layout

\end_deeper
\begin_layout Itemize
Partir d'un reseau aléatoire non linéaire (nx.random_geometric_graph), faire
 du clustering aléatoire, chaque cluster deviendra une couche de neurones
\end_layout

\begin_layout Standard
But : retrouver des architectures existantes (si optimales) ?
\end_layout

\begin_layout Part*
Résultats
\end_layout

\begin_layout Part*
Discussion
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "BIBLIO/LIBRARY"

\end_inset


\end_layout

\end_body
\end_document
